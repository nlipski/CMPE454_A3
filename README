For this assignment, you've got to read and understand much of the
code.  This README file contains only some of the information that
you'll need.

1. The Renderer

1.1 How to run it

  On Linux, execute

    ./rt-working [flags] inputFilename

  The flags can be any of

    -t    turn off texture mapping
    -m    turn on mipmapping
    -d #  set maximum ray tracing depth to #

  The inputFilename is the name of a scene file.  Start with worlds/testBasic .

1.2 Options in the window

  In the rendering window, you can control the viewpoint:

    drag mouse with left button down: rotate viewpoint around object
    drag mouse up/down with right buttom down: zoom in and out
    press '+': increment the ray tracing depth
    press '-': decrement the ray tracing depth
    press 'e': output the eye position in a format that you can
	       include in your scene description file

  To help debugging:

    Click the mouse on a pixel to see the rays traced through that
    pixel.  You can use the mouse to rotate the scene to see the rays
    from a different viewpoint.  The rays are coloured:

      blue: a ray that hit an object
      grey: a ray that did not hit an object
      red:  a shadow ray that was sent toward a point light source

    The first blue ray is the ray from the eye through the pixel that
    you clicked on.  This ray won't be visible until you rotate the
    viewpoint to see this ray from the side.

1.3 How it works

  As long as you're dragging the mouse to shift the viewpoint, the scene
  will be redrawn quickly using OpenGL.  As soon as you stop dragging the
  mouse, the raytracing code is called, and eventually a raytraced image
  is shown.  You can drag the mouse again while the raytracing is being
  done; the raytracing will be restarted as soon as you stop dragging.

  This is done by having the glutIdleFunction call the raytracing code:
  With each call, one pixel's colour is computed.  If the viewpoint
  shifts, the glutDisplayFunction is called, which renders the scene
  with OpenGL and sets a flag telling the raytracing code to start again
  when next it's called.

2. Objects

  Each object provides several methods.  See, for example, triangle.h
  and triangle.cpp.  The Triangle code provides definitions for the
  virtual functions of the Object upon which it is based.  If you
  define a new object, you'll likewise have to define these functions.
  These are:

    renderGL()   This function renders the whole object using OpenGL

    rayInt(...)  This function returns the intersection point, if any,
		 of a ray and the object.  It also provides the surface
		 normal at the point of contact, and the parameter along
		 the ray at which intersection first occurs.

    textureColour(...)  This function returns the texture colour of the
		 object at a given position.  Note that the virtual function
		 in Object.h by default returns white.  You've got to define
		 this in your own objects for textures to work.

    input()      This function reads your object from a file, assuming it's
		 the next thing to be read in the file.  It only reads the
		 part of the object description that is unique to your object;
		 The material, which is common to all objects, always appears
		 at the end of your object description and is read by another,
		 already-implemented, function.  See Triangle::input() for an
		 example, and see Object::operator>> to see how it's called.

    output()     This function outputs your object.  As with input(), it only
		 outputs the part that is unique to your object; the material
		 is output by Object::operator<<.

  Every object stores a material, and additional data that defines the particular
  object.  See how the Triangle and Sphere are built upon the Object.

3. Code

  All of the the important raytracing functions are in scene.cpp.  Make sure that
  you understand everything in that file.  The renderRT() function calculates the
  (raytraced) colour of the next pixel, and stores it.  The renderGL() function
  renders the whole scene immediately, by calling the renderGL() functions of 
  the objects in the scene.

4. Input File Format

  The scene description is stored in a file.  See testInput,
  testInputPNG, and testPhong for examples and for the specific
  format. The scene description consists (so far) of these objects:

    sphere
    triangle
    wavefront

  In the scene description, you can define other things, like:

    material   A material has a name and the standard material
	       properties (Ka, Kd, Ks, n, g, Ie, alpha).  It also can
	       (optionally) have a texture map and a bump map.  Code
	       is provided to read and store these maps.  The bump
	       mapping code isn't implemented, though.

    eye        This just defines the camera parameters.

    light      This defines the position and colour of a light.  You may
	       have as many lights as you wish (two or three is
	       usually good).
